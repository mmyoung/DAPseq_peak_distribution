{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pybedtools import BedTool\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_file = \"/clusterfs/jgi/groups/gentech/homes/romalley/full_DAPseq_annotation/test_peak.bed\"  # Input peak file with 'tf' column\n",
    "gene_file = \"/clusterfs/jgi/groups/gentech/seqtech/plant_multidap_data/genomes/annotations/Arabidopsis_thaliana_Col-0_cds_primary.gff\"  # File with gene coordinates\n",
    "\n",
    "# Load the gene coordinates and peaks as Pandas DataFrames\n",
    "genes = pd.read_csv(gene_file, sep=\"\\t\", header=None, names=[\"chrom\", \"source\", \"region\", \"start\", \"end\", \"score\", \"strand\", \"idx\", \"gene_name\"])\n",
    "peaks = pd.read_csv(peak_file, sep=\"\\t\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate common bins (as defined earlier)\n",
    "def generate_bins(start, end, num_bins, bin_prefix):\n",
    "    bin_size = (end - start) // num_bins\n",
    "    return [(start + i * bin_size, start + (i + 1) * bin_size, f\"{bin_prefix}_{i+1}\") for i in range(num_bins)]\n",
    "\n",
    "# List to store all bins\n",
    "all_bins = []\n",
    "\n",
    "# Loop through each gene and align to common bins\n",
    "for _, row in genes.iterrows():\n",
    "    chrom = row[\"chrom\"]\n",
    "    gene_start, gene_end = row[\"start\"], row[\"end\"]\n",
    "    strand = row[\"strand\"]\n",
    "\n",
    "    # Define regions for upstream, genebody, and downstream\n",
    "    if strand == \"+\":\n",
    "        upstream_start, upstream_end = gene_start - 2000, gene_start\n",
    "        downstream_start, downstream_end = gene_end, gene_end + 2000\n",
    "    else:  # Reverse for \"-\" strand\n",
    "        upstream_start, upstream_end = gene_end, gene_end + 2000\n",
    "        downstream_start, downstream_end = gene_start - 2000, gene_start\n",
    "        gene_start, gene_end = gene_end, gene_start  # Flip start/end for consistency\n",
    "\n",
    "    # Generate bins for upstream, genebody, and downstream\n",
    "    upstream_bins = generate_bins(upstream_start, upstream_end, 20, \"bin\")\n",
    "    genebody_bins = generate_bins(gene_start, gene_end, 10, \"bin\")\n",
    "    downstream_bins = generate_bins(downstream_start, downstream_end, 20, \"bin\")\n",
    "\n",
    "    # Add chromosome and bin coordinates to the list\n",
    "    for start, end, bin_name in upstream_bins + genebody_bins + downstream_bins:\n",
    "        all_bins.append((chrom, start, end, bin_name))\n",
    "\n",
    "# Create a DataFrame of all common bins\n",
    "bins_df = pd.DataFrame(all_bins, columns=[\"chrom\", \"start\", \"end\", \"bin_name\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>bin_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chr1</td>\n",
       "      <td>1760</td>\n",
       "      <td>1860</td>\n",
       "      <td>bin_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chr1</td>\n",
       "      <td>1860</td>\n",
       "      <td>1960</td>\n",
       "      <td>bin_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chr1</td>\n",
       "      <td>1960</td>\n",
       "      <td>2060</td>\n",
       "      <td>bin_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chr1</td>\n",
       "      <td>2060</td>\n",
       "      <td>2160</td>\n",
       "      <td>bin_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chr1</td>\n",
       "      <td>2160</td>\n",
       "      <td>2260</td>\n",
       "      <td>bin_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073895</th>\n",
       "      <td>ChrM</td>\n",
       "      <td>365586</td>\n",
       "      <td>365686</td>\n",
       "      <td>bin_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073896</th>\n",
       "      <td>ChrM</td>\n",
       "      <td>365686</td>\n",
       "      <td>365786</td>\n",
       "      <td>bin_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073897</th>\n",
       "      <td>ChrM</td>\n",
       "      <td>365786</td>\n",
       "      <td>365886</td>\n",
       "      <td>bin_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073898</th>\n",
       "      <td>ChrM</td>\n",
       "      <td>365886</td>\n",
       "      <td>365986</td>\n",
       "      <td>bin_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073899</th>\n",
       "      <td>ChrM</td>\n",
       "      <td>365986</td>\n",
       "      <td>366086</td>\n",
       "      <td>bin_20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7073900 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chrom   start     end bin_name\n",
       "0        Chr1    1760    1860    bin_1\n",
       "1        Chr1    1860    1960    bin_2\n",
       "2        Chr1    1960    2060    bin_3\n",
       "3        Chr1    2060    2160    bin_4\n",
       "4        Chr1    2160    2260    bin_5\n",
       "...       ...     ...     ...      ...\n",
       "7073895  ChrM  365586  365686   bin_16\n",
       "7073896  ChrM  365686  365786   bin_17\n",
       "7073897  ChrM  365786  365886   bin_18\n",
       "7073898  ChrM  365886  365986   bin_19\n",
       "7073899  ChrM  365986  366086   bin_20\n",
       "\n",
       "[7073900 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the peaks DataFrame based on unique 'tf' values\n",
    "unique_tfs = peaks['tf'].unique()\n",
    "\n",
    "# Create a dictionary to store results for each TF\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       15645942\n",
       "1       15645942\n",
       "2       15643646\n",
       "3       15643234\n",
       "4       15880261\n",
       "          ...   \n",
       "1994    12843672\n",
       "1995      546383\n",
       "1996      545864\n",
       "1997      546383\n",
       "1998      544833\n",
       "Length: 1999, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_peaks['peak_start'] + tf_peaks['peak_summit'] - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = \"AT1G01060\"\n",
    "tf_peaks = peaks[peaks['tf'] == tf]\n",
    "tf_peak_tmp = pd.DataFrame()\n",
    "tf_peak_tmp['chr'] = tf_peaks['peak_chr']\n",
    "tf_peak_tmp['start'] = tf_peaks['peak_start'] + tf_peaks['peak_summit'] - 10\n",
    "tf_peak_tmp['end'] = tf_peaks['peak_start'] + tf_peaks['peak_summit'] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_peak_tmp.to_csv(\"tf_peak_tmp.bed\",index=False, sep=\"\\t\", header=False)\n",
    "tf_peaks_bed = BedTool(\"tf_peak_tmp.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(tf_peak_tmp.bed)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_peaks_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tf in unique_tfs:\n",
    "    # Subset the peaks DataFrame for the current TF\n",
    "    tf_peaks = peaks[peaks['tf'] == tf]\n",
    "    tf_peaks_tmp = pd.DataFrame(tf_peaks['peak_chr'],tf_peaks['peak_start'] + tf_peaks['peak_summit'] - 10, tf_peaks['peak_start'] + tf_peaks['peak_summit'] + 10)\n",
    "\n",
    "    # Convert TF-specific peaks to a BEDTool object\n",
    "    tf_peaks_bed = BedTool(tf_peaks_tmp.to_csv(index=False, sep=\"\\t\", header=False))\n",
    "\n",
    "    # Intersect to count peaks in each bin (using pre-generated bins)\n",
    "    common_bins_bed = BedTool(common_bins_file)\n",
    "    overlap = common_bins_bed.intersect(tf_peaks_bed, c=True)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    overlap_df = pd.read_csv(overlap.fn, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\", \"bin_name\", \"peak_count\"])\n",
    "\n",
    "    # Summarize peak counts by bin name\n",
    "    summary_df = overlap_df.groupby(\"bin_name\")[\"peak_count\"].sum().reset_index()\n",
    "\n",
    "    # Sort bins numerically\n",
    "    summary_df[\"bin_number\"] = summary_df[\"bin_name\"].str.extract(\"(\\d+)\").astype(int)\n",
    "    summary_df = summary_df.sort_values(\"bin_number\")\n",
    "\n",
    "    # Add the TF label for the current subset\n",
    "    summary_df[\"tf\"] = tf\n",
    "\n",
    "    # Append the result for this TF to the list of results\n",
    "    all_results.append(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
